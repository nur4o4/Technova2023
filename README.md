# The Problem that Propelled us to Creating SafeGuard + My contributions

## The Problem
The digital world is an unsafe space for minority groups and youths, who are constantly exposed to triggering or inappropriate content from their most used social media platforms. With the introduction of AI (Artificial Intelligence), there is a dark side where it is being misused for malicious reasons to dox sensitive information, leak private photos, and scam naive users. How might we create a safer space on the internet for everyone, especially women and vulnerable sectors, while educating on digital literacy and empowering our users to take control of their mental health in their digital space?

Figma File: https://www.figma.com/proto/sJ7I5VB2b3abiDhrhsE7M6/SafeGuard?type=design&node-id=15-91&t=izo7jvsqE8xxvck1-1&scaling=scale-down&page-id=0%3A1&starting-point-node-id=15%3A91&mode=design

## My contributions
I wrote main.py, which is an AI model which reads in texts and is trained based on a set of data to determine wether the entered text needs to be flagged as potentially triggering. I also made sure it is able to read in images and videos as well, by reading text from images and importing video transcripts.
